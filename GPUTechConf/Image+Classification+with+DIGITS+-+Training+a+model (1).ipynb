{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli/\"> <img src=\"files/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "# Image Classification with DIGITS\n",
    "                                     An introduction to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll learn to **train** a **neural network** using clean **labeled data**. We'll introduce deep learning through the task of **supervised image classification,** where, given many images and their labels, you'll build a tool that can *predict* labels of *new* images.\n",
    "\n",
    "The intent is to build the skills to start experimenting with deep learning. You'll examine:\n",
    "\n",
    "- What it means to *train* vs. to *program*\n",
    "- The role of data in artificial intelligence\n",
    "- How to load data for training a neural network\n",
    "- The role of a *network* in deep learning\n",
    "- How to train a model with data\n",
    "\n",
    "At the end of this lab, you'll have a trained neural network that can successfully classify images to solve a classic deep learning challenge:  \n",
    "\n",
    "**How can we digitize handwriting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training vs. programming\n",
    "\n",
    "The fundamental difference between artificial intelligence (AI) and traditional programing is that AI *learns* while traditional algorithms are *programmed.* Let's examine the difference through an example:\n",
    "\n",
    "Imagine you were asked to give a robot instructions to make a sandwich using traditional computer programming, instruction by instruction. How might you start?\n",
    "\n",
    "Maybe something like:   \n",
    "<code>Add two pieces of bread to an empty plate.</code>  \n",
    "\n",
    "Run the code below to see what the robot might do with your first instruction. To run code, click on **In [ ]** and press **Shift + Enter**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "readyPlate = 2*bread + emptyPlate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You likely got a \"NameError.\" How would you then work to define \"bread\" to your robot? Not to mention other ingredients and how to combine them?\n",
    "\n",
    "Computers only \"see\" images as the amount of red, blue, and green at each pixel. Everything else we want them to know, we would have had to describe in terms of pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial intelligence takes a different approach. Instead of providing instructions, we provide examples. Above, we could *show* our robot thousands of labeled images of bread and thousands of labeled images of other objects and ask our robot to learn the difference. Our robot could then build its own program to identify new groups of pixels (images) as bread. \n",
    "\n",
    "![](bread.png)\n",
    "\n",
    "Instead of instructions, we now need data and computers designed to learn.\n",
    "\n",
    "### The Big Bang in Machine Learning\n",
    "\n",
    "- **Data:** In the era of big data, we create ~2.5 quintillion bytes of data per day. Free datasets are available from places like [Kaggle.com](https://www.kaggle.com/datasets) and [UCI](https://archive.ics.uci.edu/ml/datasets.html). Crowdsourced datasets are built through creative approaches - e.g. Facebook asking users to \"tag\" friends in their photos to create labeled facial recognition datasets. More complex datasets are generated manually by experts - e.g. asking radiologists to label specific parts of the heart.\n",
    "- **Computers designed to learn - software:** Artificial neural networks are inspired by the human brain. Like their biological counterparts, they are structured to understand (and represent) complex concepts, but their biggest strength is their ability to learn from data and feedback. The \"deep\" in deep learning refers to many layers of artificial neurons, each of which contribute to the network's performance.\n",
    "- **Computers designed to learn - hardware:** The computing that powers deep learning is intensive, but not complex. Processing huge datasets through deep networks is made possible by parallel processing, a task tailor made for the GPU.\n",
    "\n",
    "So how do we expose artificial neural networks to data?\n",
    "\n",
    "By the end of this lab, you'll know how to load data into a deep neural network to create a trained model that is capable of solving problems with what it learned, not what a programmer told it to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a network to recognize handwritten digits\n",
    "\n",
    "Since a computer \"sees\" images as collections of pixel values, it can't do anything with visual data unless it learns what those pixels represent. \n",
    "\n",
    "What if we could easily convert handwritten digits to the digital numbers they represent? \n",
    "\n",
    "1. We could help the post office sort piles of mail by post code. This is the problem that motivated [Yann LeCun](http://yann.lecun.com/). He and his team put together the dataset and neural network that we'll use today and painstakingly pioneered much of what we know now about deep learning.\n",
    "2. We could help teachers by automatically grading math homework. This the problem that motivated the team at [answer.ky](http://answer.ky/), who used Yann's work to easily solve a real world problem using a workflow like what we'll work through now.\n",
    "3. We could solve countless other challenges. What will you build?\n",
    "\n",
    "We're going to train a deep neural network to recognize handwritten digits 0-9. This challenge is called \"image classification,\" where our network will be able to decide which image belongs to which class, or group. \n",
    "\n",
    "For example:  \n",
    "The following image should belong to the class '4':\n",
    "\n",
    "<img src=\"test_images/image-4-1.jpg\" width=\"64px\" /> <div style=\"text-align:center;\"></div>\n",
    "\n",
    "whereas this next image should belong to the class '2':\n",
    "\n",
    "<img src=\"test_images/image-2-1.jpg\" width=\"64px\" /> <div style=\"text-align:center;\"></div>\n",
    "\n",
    "It's important to note that this workflow is common to most image classification tasks, and is a great entry point to learning how to solve problems with Deep Learning.\n",
    "\n",
    "Let's start.\n",
    "\n",
    "### Load and organize data\n",
    "\n",
    "Let's start by bringing our data, in this case, thousands of images, into our learning environment. We're going to use a tool called DIGITS, where we can visualize and manage our data. \n",
    "\n",
    "First, open DIGITS in a new tab using the following link.\n",
    "\n",
    "### <a href=\"/digits/\" target=\\\"_blank\\\">Open DIGITS</a>.\n",
    "\n",
    "#### Loading our first dataset\n",
    "\n",
    "When you start DIGITS, you will be taken to the home screen where you can create new datasets or new models. \n",
    "\n",
    "Begin by selecting the **Datasets** tab on the left.\n",
    "\n",
    "![](DIGITSdatasetHome.PNG)\n",
    "\n",
    "Since we want our network to tell us which \"class\" each image belongs to, we ask DIGITS to prepare a \"classification\" image dataset by selecting \"Classification\" from the \"Images\" menu on the right.\n",
    "\n",
    "At this point you may need to enter a username.  If requested, just enter any name in lower-case.\n",
    "\n",
    "#### Loading and organizing our data\n",
    "\n",
    "You'll see that you've got a lot of options around *how* to load a dataset. For this first runthrough, we're going to simplify and only fill out two fields. \n",
    "\n",
    "1. Copy and paste the following filepath into the field \"Training Images\":  <code>/data/train_small</code>\n",
    "2. Name the dataset so that you can find it. We've chosen: <code>Default Options Small Digits Dataset</code>\n",
    "\n",
    "Don't see \"Training Images?\" Click \"DIGITS\" on the top left and select \"Datasets\" before selecting \"Images\" and \"Classification.\"\n",
    "\n",
    "Note that we've already downloaded the dataset to the computer where DIGITS is running. You'll have a chance to explore it shortly and will learn methods for accessing data as you work through our labs. \n",
    "\n",
    "![](FirstDataSetSettings.png)\n",
    "\n",
    "Then press \"Create.\"\n",
    "\n",
    "DIGITS is now creating your dataset from the folder. Inside the folder <code>train_small</code> there were 10 subfolders, one for each class (0, 1, 2, 3, ..., 9). All of the handwritten training images of '0's are in the '0' folder, '1's are in the '1' folder, etc.  \n",
    "\n",
    "Explore what our data looks like by selecting \"Explore the db\".\n",
    "\n",
    "#### Your data\n",
    "\n",
    "While there is an endless amount of analysis that we could do on the data, make sure you at least note the following:\n",
    "\n",
    "1. This data is *labeled.* Each image in the dataset is paired with a **label** that informs the computer what number the image represents, 0-9. We're basically providing a question with its answer, or, as our network will see it, a desired output with each input. These are the \"examples\" that our network will learn from.\n",
    "2. Each image is simply a digit on a plain background. Image classification is the task of identifying the *predominant* object in an image. For a first attempt, we're using images that only contain *one* object. We'll build skills to deal with messier data in subsequent labs. \n",
    "\n",
    "This data comes from the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset which was created by Yann LeCun. It's largely considered the \"Hello World,\" or introduction, to deep learning.\n",
    "\n",
    "### Learning from our data - Training a neural network\n",
    "\n",
    "Next, we're going to use our data to *train* an artificial neural network. Like its biological inspiration, the human brain, artificial neural networks are learning machines. Also like the brain, these \"networks\" only become capable of solving problems with experience, in this case, interacting with data. Throughout this lab, we'll refer to \"networks\" as untrained artificial neural networks and \"models\" as what networks become once they are trained (through exposure to data).\n",
    "\n",
    "![](networktomodel.PNG)\n",
    "\n",
    "For image classification (and some other tasks), DIGITS comes pre-loaded with award-winning networks. As we take on different challenges in subsequent labs, we'll learn more about selecting networks and even building our own. However, to start, weighing the merits of different networks would be like arguing about the performance of different cars before driving for the first time. Building a network from scratch would be like building your own car. Let's drive first. We'll get there. \n",
    "\n",
    "Go to the tab where DIGITS is still open and return to the main screen by clicking \"DIGITS\" on the top left of the screen.\n",
    "\n",
    "Creating a new model in DIGITS is a lot like creating a new dataset. From the home screen, the \"Models\" tab will be pre-selected. Click \"Images\" under \"New Model\" and select \"Classification\", as we're creating an image classification model to match our image classification dataset and image classification task.\n",
    "\n",
    "![](newmodelselect.PNG)\n",
    "\n",
    "Again, for this first round of training let's keep it simple. The following are the fewest settings you could possibly set to successfully train a network.\n",
    "\n",
    "1. We need to choose the dataset we just created. Select our **Default Options Small Digits Dataset** dataset.\n",
    "2. We need to tell the network how long we want it to train. An **epoch** is one trip through the entire training dataset. Set the number of **Training Epochs** to 5 to give our network enough time to learn something, but not take all day. This is a great setting to experiment with. \n",
    "3. We need to define which network will *learn* from our data. Since we stuck with default settings in creating our dataset, our database is full of 256x256 color images. Select the network **AlexNet**, if only because it expects 256x256 color images.\n",
    "4. We need to name the model, as hopefully we'll do a lot of these. We chose **My first model.**\n",
    "\n",
    "![](1stmodeltrain.png)\n",
    "\n",
    "When you have set all of these options, press the Create button.  \n",
    "\n",
    "You are now training your model! For this configuration, the model training should complete in less than 5 minutes. You can either watch it train, continue reading, or grab a cup of coffee. \n",
    "\n",
    "When done, the Job Status on the right will say \"Done\", and your training graph should look something like:\n",
    "\n",
    "![](graphfromfirsttraining.png)\n",
    "\n",
    "We'll dig into this graph as a tool for improvement, but the bottom line is that after 5 minutes of training, we have built a model that can map images of handwritten digits to the number they represent with an accuracy of about 87%! \n",
    "\n",
    "Let's test the ability of the model to identify **new** images.  \n",
    "\n",
    "### Inference\n",
    "\n",
    "Now that our neural network has learned something, *inference* is the process of making decisions based on what was learned. The power of our trained model is that it can now classify **unlabeled** images. \n",
    "\n",
    "![](trainingwithinferencevisualization.PNG)\n",
    "\n",
    "We'll use DIGITS to test our trained model. At the bottom of the model window, you can test a single image or a list of images.  On the left, type in the path <code>/data/test_small/2/img_4415.png</code> in the Image Path text box. Select the **Classify One** button.  After a few seconds, a new window is displayed with the image and information about its attempt to classify the image. \n",
    "\n",
    "![](classifyoneunlabeled.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! (Try again if it didn't). You took an untrained neural network, exposed it to thousands of *labeled* images, and it now has the ability to accurately predict the *class* of *unlabeled* images. Congratulations!\n",
    "\n",
    "Note that that same workflow would work with almost any image classification task. You could train AlexNet to classify images of dogs from images of cats, images of you from images of me, etc. If you have extra time at the end of this lab, theres another dataset with 101 different classes of images where you can experiment.\n",
    "\n",
    "While you have been successful with this introductory task, there is a lot more to learn.\n",
    "\n",
    "In the next notebook, you will work to define and improve performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Continue to the next notebook](Image%20Classification%20with%20DIGITS%20-%20Improving%20Performance.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"files/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
